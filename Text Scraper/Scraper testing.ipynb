{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting url from extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# import readability\n",
    "from readability import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.foxnews.com/politics/judge-grants-19-ags-preliminary-injunction-against-doge-access-treasury-payment-system\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from readability import Document\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/90.0.4430.93 Safari/537.36\")\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_with_readability(html_content):\n",
    "    # Use readability to extract the main content and title\n",
    "    doc = Document(html_content)\n",
    "    summary_html = doc.summary()\n",
    "    title = doc.title()\n",
    "    \n",
    "    # Parse the summary HTML using BeautifulSoup\n",
    "    soup = BeautifulSoup(summary_html, \"lxml\")\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    \n",
    "    # Clean up the extracted text:\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    clean_lines = [line for line in lines if line]\n",
    "    clean_text = \"\\n\".join(clean_lines)\n",
    "    clean_text = re.sub(r'\\s{2,}', ' ', clean_text)\n",
    "    \n",
    "    return clean_text, title\n",
    "\n",
    "@app.route('/scrape', methods=['POST'])\n",
    "def scrape():\n",
    "    # Get JSON data from the POST request\n",
    "    data = request.get_json()\n",
    "    url = data.get(\"url\")\n",
    "    if not url:\n",
    "        return jsonify({\"error\": \"Missing URL parameter\"}), 400\n",
    "\n",
    "    # Fetch the webpage content\n",
    "    html_content = fetch_webpage(url)\n",
    "    if not html_content:\n",
    "        return jsonify({\"error\": \"Failed to fetch webpage content\"}), 500\n",
    "\n",
    "    # Parse the webpage content using readability and BeautifulSoup\n",
    "    parsed_text, title = parse_with_readability(html_content)\n",
    "\n",
    "    # Prepare the result dictionary\n",
    "    result = {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"text\": parsed_text\n",
    "    }\n",
    "\n",
    "    # Save the result to a JSON file\n",
    "    try:\n",
    "        with open(\"scraped_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON to file: {e}\")\n",
    "\n",
    "    # Return the result as a JSON response\n",
    "    return jsonify(result)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comms with front end\n",
    "\n",
    "recieve url from chrome extension\n",
    "\n",
    "Turn into a json payload\n",
    "\n",
    "curl or something the payload into the thingy ma bob\n",
    "\n",
    "take the output and send to liam's nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_Scraper_Venv_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
